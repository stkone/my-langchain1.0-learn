"""
医疗整体评估样例
"""

import os

from datasets import Dataset
from langchain_community.chat_models import ChatTongyi
from langchain_community.embeddings import DashScopeEmbeddings
from ragas import evaluate
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.llms import LangchainLLMWrapper
from ragas.metrics import (
    answer_relevancy,
    faithfulness,
    context_recall,
    context_precision,
)

from common_ai.ai_variable import ALI_TONGYI_API_KEY_OS_VAR_NAME

"""
============================================================
Ragas 评估框架使用说明
============================================================

【Ragas是什么？】
Ragas是一个专门用于评估RAG（检索增强生成）系统质量的框架。
它通过对比四个关键要素来计算评估指标：
  - question: 用户提出的问题
  - answer: RAG系统生成的回答
  - contexts: 检索到的知识库文档片段
  - ground_truth: 人工标注的标准答案（参考答案）

【评估原理】
Ragas使用大模型作为"评判员"，通过精心设计的提示词模板，
让大模型对比上述四个要素，输出量化的评估分数。

【核心评估指标】
1. Context Precision (上下文精确率): 检索到的文档中有多少是相关的
2. Context Recall (上下文召回率): 相关文档被检索到了多少
3. Faithfulness (忠实度): 生成的回答是否忠实于检索到的文档
4. Answer Relevancy (回答相关性): 生成的回答与问题的相关程度

【使用流程】
步骤1: 准备测试数据（question/answer/contexts/ground_truth）
步骤2: 配置评估模型（LLM + Embeddings）
步骤3: 调用evaluate()执行评估
步骤4: 分析评估结果

============================================================
"""
# ============================================================
# 步骤1: 构建评估数据集
# ============================================================
# 评估数据集需要包含4个核心字段，每个字段是一个列表，列表长度必须一致

# 【字段1】question: 用户向RAG系统提出的问题
questions = [
    '坤泰胶囊的性状',
    '如何鉴别三七三醇皂替',
    '如何制作枇杷止咳软胶囊',
    '枇杷止咳颗粒的成分是什么？',
    '清肺润燥，止咳化痰。用于肺热燥咳，且用枇杷叶制作的药是什么？',
    '板蓝根1500g        大青叶2250g是哪个药的处方',
    '板蓝根茶能干什么？',
    '板蓝根颗粒的储存条件是什么？',
    '松龄血脉康胶囊的用法与用量',
    '刺五加浸膏150g是不是刺五加片的处方'
]
# 【字段4】ground_truth: 人工标注的标准答案（参考答案）
# 用于评估生成回答的质量，是评估的"黄金标准"
ground_truth = [
    '坤泰胶囊的性状是外表为硬胶囊，内容物为黄褐色或棕褐色的粉末,味苦。',
    '''要鉴别三七三醇皂替，可以按照以下步骤进行：
    样品准备：取适量的三七三醇皂替样品，按含量测定的方法处理，制备供试品。
    对照品准备：准备对照品，包括三七皂昔（R）、人参皂昔（Rg）、人参皂昔（Re''',
    '''枇杷止咳胶囊的制法是枇杷叶342g，罂粟壳250g，
    百部75g，白前45g，
    桑白皮30g，桔梗29g，薄荷脑0.8g，
    以上七味，除薄荷脑外，其余枇杷叶等六味，加 水煎煮二次，每次3小时，滤过，合并滤液，
    浓缩成稠膏状，加 入适量淀粉，混匀，干燥，粉碎，过筛；另取薄荷脑，用少量乙醇 溶解后喷入，
    混匀，装入胶囊，制成1000粒，即得。''',
    '枇杷止咳颗粒的成分是枇杷叶228g,罂粟壳167g,百部50g,白前30g,桑白皮20g,桔梗19g,薄荷脑0.53g',
    '是枇杷叶膏',
    '板蓝根1500g大青叶2250g是板蓝大青片的处方',
    '板蓝根茶能清热解毒，凉血利咽。用于肺胃热盛所致的咽喉肿痛、口咽干燥、腮部肿胀;急性扁桃体炎、腮腺炎等上述症候者。',
    '板蓝根颗粒需要在密封条件下储存',
    '松龄血脉康胶囊的用法是口服。一次3粒，一日3次，或遵医嘱。',
    '刺五加片的处方是刺五加浸膏150g',
]
# 【字段3】contexts: RAG系统检索到的知识库文档片段
# 这是一个二维列表，每个问题对应一个文档列表（支持多文档检索）
# contexts用于评估检索质量和回答的忠实度
contexts = [
    ['''【性状】 本品为硬胶囊，内容物为黄褐色或棕褐色的粉 末;味苦。'''],
    ['''【鉴别】取本品，照〔含量测定〕项下的方法试验,供试品 色谱中应呈现与对照品三七皂昔R】、人参皂昔Rg】、
    人参皂 昔Re色谱峰保留时间相同的色谱峰。'''],
    ['''枇杷止咳胶囊:【处方】 枇杷叶342g 罂粟壳250g百部75g 白前45g 桑白皮30g 桔梗29g 薄荷脑0.8g
    【制法】以上七味，除薄荷脑外，其余枇杷叶等六味，加 水煎煮二次，每次3小时，滤过，合并滤液，浓缩成稠膏状，
    加入适量淀粉，混匀，干燥，粉碎，过筛；另取薄荷脑，用少量乙醇 溶解后喷入，混匀，装入胶囊，制成1000粒，即得。'''],
    ['''枇杷止咳颗粒:【处方】 枇杷叶228g  罂粟壳167g 百部50g  白前30g 桑白皮20g  桔梗19g 薄荷脑0. 53g'''],
    ['''枇杷叶膏:【用法与用量】口服。一次9〜15g, 一日2次。'''],
    ['''板蓝大青片:【处方】 板蓝根1500g        大青叶2250g'''],
    ['''板蓝根茶:【功能与主治】清热解毒，凉血利咽。用于肺胃热盛所 致的咽喉肿痛、口咽干燥、腮部肿胀;急性扁桃体炎、腮腺炎见上述证候者。'''],
    ['''板蓝根颗粒:【贮藏】密封'''],
    ['''松龄血脉康胶囊:【用法与用量】口服。一次3粒，一日3次，或遵医嘱。'''],
    ['''刺五加片:【处方】刺五加浸膏150g'''],

]
# 【字段2】answer: RAG系统实际生成的回答
# 这是我们要评估的目标输出
answers = [
    '坤泰胶囊的性状为：硬胶囊，内容物为黄褐色或棕褐色的粉末；味苦。',
    '''要鉴别三七三醇皂替（Notoginseng Triol Saponins），可以通过以下方法：
    外观特征：鉴别时观察其外观，本品为浅黄棕色至黄棕色的粉末，无臭，味道苦。
    色谱鉴别：取适量样品，进行色谱分析。供试品的色谱中应出现与对照品（三七皂苷R1，人参皂苷Rg1，人参皂苷Re）
    相同保留时间的色谱峰。含量测定：采用高效液相色谱法测定本品中的主要成分含量：人参皂苷Rg1的含量不得少于50%。
    人参皂苷Re的含量不得少于6.0%。三七皂苷R1的含量不得少于11.0%。检查指标：干燥失重不得超过7.0%。炽灼残渣不得超过0.9%。
    重金属含量检查不得超过20mg/kg。指纹图谱：通过高效液相色谱法获得指纹图谱，并计算其与对照指纹图谱的相似度，
    确保相似度不低于0.90。这些方法可以帮助您准确鉴别三七三醇皂替的质量和纯度。''',
    '''要制作枇杷止咳软胶囊，您可以按照以下步骤进行：材料准备
    处方药材：
    枇杷叶 342g
    百部 75g
    罂粟壳 250g
    白前 45g
    桑白皮 30g
    桔梗 28.5g
    薄荷脑 0.8g
    制作流程：
    药材煎煮：
    将枇杷叶、百部、罂粟壳、白前、桑白皮和桔梗六种药材加水煎煮两次，每次3小时。
    合并两次的煎液，滤过后静置12小时，再次滤过，得到清液。
    浓缩与干燥：
    将滤液浓缩至膏状，然后干燥，粉碎成细粉。
    混合患料：
    将薄荷脑细粉逐渐加入到聚乙二醇400中，均匀混合。
    制成软胶囊：
    将混合物制成软胶囊，每千粒为一剂。
    性状
    该软胶囊为棕褐色液体，具有微香气，味道凉且微苦涩。
    适应症
    本品用于止咳化痰，适用于痰热蕴肺所致的咳嗽与咯痰，特别是支气管炎患者的相关症状。
    用法与用量
    口服，每次2粒，一日3次。
    贮藏
    应密封保存。
    以上就是制作枇杷止咳软胶囊的完整步骤和相关信息。''',
    '''枇杷止咳颗粒的成分包括以下几种药材和成分：
    枇杷叶 228g
    罂粟壳 167g
    百部 50g
    白前 30g
    桑白皮 20g
    桔梗 19g
    薄荷脑 0.53g
    这些成分的组合用来止咳化痰，主要适用于因痰热蕴肺引起的咳嗽和咯痰等症状。''',
    '''用于清肺润燥，止咳化痰，适用于肺热燥咳，并且是由枇杷叶制作的药是“枇杷叶膏”''',
    '''板蓝根1500g和大青叶2250g是“板蓝大青片”的处方。''',
    '''板蓝根茶的主要功效包括清热解毒、凉血利咽。它常用于治疗温疫时的中毒症状，如发热咽痛、温毒发斑、腮腺炎、口腔炎症、大头瘟疫、丹毒和痈肿等。在使用时，推荐的用法与用量为每次9到15克。总体来说，板蓝根茶适合在体内有火热症状时饮用，以帮助缓解相关不适。。''',
    '''板蓝根颗粒的储存条件为：密封保存。建议将其置于阴凉干燥的地方以确保有效性''',
    '松龄血脉康胶囊的用法与用量为：口服，一次3粒，一日3次，或遵医嘱。',
    '''是的，刺五加浸膏150g是刺五加片的处方之一。在刺五加片的制法中明确指出使用刺五加浸膏作为主要成分。因此，刺五加浸膏与刺五加片有直接的关联''']

# ============================================================
# 将四个字段组装成字典，后续转换为Hugging Face Dataset格式
# ============================================================
data = {
    "question": questions,      # 问题列表
    "answer": answers,          # RAG生成的回答列表
    "contexts": contexts,       # 检索到的原始文档片段列表（二维）
    "ground_truth": ground_truth  # 标准答案列表
}

# ============================================================
# 步骤2: 配置评估所需的模型
# ============================================================

# 【2.1】配置LLM（大语言模型）
# Ragas使用LLM来执行评估判断，例如：
# - 判断回答是否忠实于文档（Faithfulness）
# - 判断回答是否与问题相关（Answer Relevancy）
# - 判断检索到的文档是否相关（Context Precision/Recall）
model = ChatTongyi()

# 【2.2】配置Embedding模型（嵌入模型）
# Ragas在某些指标（如Answer Relevancy）中需要计算语义相似度
llm_embeddings = DashScopeEmbeddings(
    model="text-embedding-v3",  # 使用阿里云DashScope的向量嵌入模型
    dashscope_api_key=os.getenv(ALI_TONGYI_API_KEY_OS_VAR_NAME)  # 从环境变量获取API密钥
)
# 【2.3】使用Ragas的Wrapper包装LangChain模型
# Ragas需要特定接口的模型对象，LangchainLLMWrapper和LangchainEmbeddingsWrapper
# 用于将LangChain的模型适配为Ragas可用的接口
vllm = LangchainLLMWrapper(model)
vllm_e = LangchainEmbeddingsWrapper(llm_embeddings)

# 【2.4】将数据转换为Hugging Face Dataset格式
# Ragas的evaluate函数要求输入为datasets.Dataset类型
dataset = Dataset.from_dict(data)

# ============================================================
# 步骤3: 执行Ragas评估
# ============================================================

# 【评估指标说明】
# 1. context_precision: 上下文精确率
#    - 衡量：检索到的文档中有多少是真正相关的
#    - 计算：相关文档数 / 检索到的总文档数
#
# 2. context_recall: 上下文召回率
#    - 衡量：所有相关文档中有多少被成功检索到
#    - 计算：检索到的相关文档数 / 所有相关文档数
#
# 3. faithfulness: 忠实度（幻觉检测）
#    - 衡量：生成的回答是否基于检索到的文档，是否存在"幻觉"
#    - 原理：LLM判断answer中的每个陈述是否能在contexts中找到依据
#
# 4. answer_relevancy: 回答相关性
#    - 衡量：生成的回答是否与问题直接相关
#    - 原理：基于embedding计算answer与question的语义相似度

result = evaluate(
    dataset=dataset,          # 评估数据集
    llm=vllm,                 # 用于评估的LLM
    embeddings=vllm_e,        # 用于评估的Embedding模型
    metrics=[                 # 选择要计算的评估指标
        context_precision,    # 上下文精确率
        context_recall,       # 上下文召回率
        faithfulness,         # 忠实度（回答是否基于文档）
        answer_relevancy,     # 回答与问题的相关性
    ],
    raise_exceptions=False    # 遇到错误不抛出异常，继续评估其他样本
)

# ============================================================
# 步骤4: 输出和分析评估结果
# ============================================================

# 将评估结果转换为Pandas DataFrame，便于查看和分析
# 结果包含每个样本的各指标分数，以及平均分
df = result.to_pandas()

# 打印评估结果到控制台
print(df)

# 将结果保存为CSV文件，便于后续分析和报告生成
df.to_csv('ragas_reval.csv', index=True)

# ============================================================
# 【结果解读指南】
# - 每个指标的分数范围是0-1，越接近1表示表现越好
# - context_precision低：检索器返回了太多不相关的文档
# - context_recall低：检索器漏掉了重要的相关文档
# - faithfulness低：模型产生了"幻觉"，回答了文档中没有的信息
# - answer_relevancy低：回答偏离了问题的核心意图
# ============================================================
